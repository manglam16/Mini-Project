{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hLdF1oit06A"
   },
   "source": [
    "# using deep learning\n",
    "We will start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DzJqzHv-LceW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:21:40.387900: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 16:21:40.666574: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 16:21:40.668193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 16:21:42.683746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "54C8Oca0LlVR"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eOvZ5uMyOtTF"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./test_reviews.csv\")\n",
    "reviews = df[:20000]\n",
    "test_reviews=df[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9946"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = 0\n",
    "pos = 0\n",
    "neu = 0\n",
    "for i in range(0,19999):\n",
    "    if(reviews['Sentiment'][i]=='positive') :\n",
    "        pos=pos+1\n",
    "    elif (reviews['Sentiment'][i]=='negative'):\n",
    "        neg=neg+1\n",
    "    elif(reviews['Sentiment'][i]=='neutral') :\n",
    "        neu=neu+1\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "YI4qnZOTPFqx",
    "outputId": "5240acf8-e34a-4857-ad0f-5b72ed9ae3b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START please give this one a miss br br &lt;UNK&gt;...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START this film requires a lot of patience be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START many animation buffs consider &lt;UNK&gt; &lt;UN...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START i generally love this type of movie how...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START like some other people wrote i'm a die ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START please give this one a miss br br <UNK>...  negative\n",
       "1  <START this film requires a lot of patience be...  positive\n",
       "2  <START many animation buffs consider <UNK> <UN...  positive\n",
       "3  <START i generally love this type of movie how...  negative\n",
       "4  <START like some other people wrote i'm a die ...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LGqg6S8OXVmV",
    "outputId": "4318016f-7ebd-4592-c630-2dbde76b80e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>&lt;START the concept of this movie is pretty com...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>&lt;START i really liked the far cry game nice gr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>&lt;START when young frances &lt;UNK&gt; &lt;UNK&gt; goes to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>&lt;START attractive husband and wife writing tea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>&lt;START being a huge die hard monkey island fan...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Reviews Sentiment\n",
       "20000  <START the concept of this movie is pretty com...  negative\n",
       "20001  <START i really liked the far cry game nice gr...  negative\n",
       "20002  <START when young frances <UNK> <UNK> goes to ...  positive\n",
       "20003  <START attractive husband and wife writing tea...  negative\n",
       "20004  <START being a huge die hard monkey island fan...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uf5XTq_hAxL6"
   },
   "outputs": [],
   "source": [
    "word_index=pd.read_csv(\"./word_indexes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE47q3yibEIM"
   },
   "source": [
    "The word index file contains mapping from words to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AbkABN8jA_Ye",
    "outputId": "9e7ba619-7176-4e44-e0a7-155ca10ed731"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woods</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words  Indexes\n",
       "0  tsukino    52009\n",
       "1  nunnery    52010\n",
       "2    sonja    16819\n",
       "3     vani    63954\n",
       "4    woods     1411"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZYF6pDzbNCe"
   },
   "source": [
    "Next we are going to convert the word_index dataframe into a python dictionary so that we can use it for converting our reviews from string to integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zuiMcF5XD65R"
   },
   "outputs": [],
   "source": [
    "word_index=dict(zip(word_index.Words,word_index.Indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FsScw2ilFqap"
   },
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"]=0\n",
    "word_index[\"<START\"]=1\n",
    "word_index[\"<UNK>\"]=2\n",
    "word_index[\"<UNUSED>\"]=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVEL7jQ6bjbV"
   },
   "source": [
    "Now we define a function review_encoder that encodes the reviews into integer format according to the mapping specified by word_index file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nay4o8dSAqbu"
   },
   "outputs": [],
   "source": [
    "def review_encoder(text):\n",
    "  arr=[word_index[word] for word in text]\n",
    "  return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3mS11cVcGhU"
   },
   "source": [
    "We split the reviews from their corresponding sentiments so that we can preprocess the reviews and sentiments separately and then later pass it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bUhde9eLE5H3"
   },
   "outputs": [],
   "source": [
    "train_data,train_labels=reviews['Reviews'],reviews['Sentiment']\n",
    "test_data, test_labels=test_reviews['Reviews'],test_reviews['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBWDVwCNdBJP"
   },
   "source": [
    "Before transforming the reviews as integers we need to tokenize or split the review on the basis of whitespaces\n",
    "For eg.the string \"The movie was wonderful\" becomes [\"The\" , \"movie\" , \"was\" , \"wonderful\" ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "frWCqvycL-w5"
   },
   "outputs": [],
   "source": [
    "train_data=train_data.apply(lambda review:review.split())\n",
    "test_data=test_data.apply(lambda review:review.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GCM_74ve7OZ"
   },
   "source": [
    "Since we have tokenized the reviews now we can apply the review_encoder function to each review and transform the reviews into integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wJLwZH1OMPJM"
   },
   "outputs": [],
   "source": [
    "train_data=train_data.apply(review_encoder)\n",
    "test_data=test_data.apply(review_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p01DiByEJ7fw"
   },
   "outputs": [],
   "source": [
    "def encode_sentiments(x):\n",
    "  if x=='positive':\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "train_labels=train_labels.apply(encode_sentiments)\n",
    "test_labels=test_labels.apply(encode_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CHEVR3TbPE_1"
   },
   "outputs": [],
   "source": [
    "train_data=keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)\n",
    "test_data=keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D1WDSfAIPs31"
   },
   "outputs": [],
   "source": [
    "model=keras.Sequential([keras.layers.Embedding(10000,16,input_length=500),\n",
    "                        keras.layers.GlobalAveragePooling1D(),\n",
    "                        keras.layers.Dense(16,activation='relu'),\n",
    "                        keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JPsQuds5QYud"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxUCLcRJQmBB",
    "outputId": "5dff0e7b-4544-48ac-fb87-4108ab34552b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6927 - accuracy: 0.5130 - val_loss: 0.6921 - val_accuracy: 0.4906\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.6901 - accuracy: 0.5755 - val_loss: 0.6878 - val_accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.6838 - accuracy: 0.7013 - val_loss: 0.6791 - val_accuracy: 0.7386\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.6694 - accuracy: 0.7581 - val_loss: 0.6584 - val_accuracy: 0.7686\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.6416 - accuracy: 0.7796 - val_loss: 0.6273 - val_accuracy: 0.7698\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.6027 - accuracy: 0.7941 - val_loss: 0.5844 - val_accuracy: 0.7988\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.5574 - accuracy: 0.8118 - val_loss: 0.5406 - val_accuracy: 0.8252\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.5102 - accuracy: 0.8371 - val_loss: 0.4974 - val_accuracy: 0.8404\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.4665 - accuracy: 0.8497 - val_loss: 0.4590 - val_accuracy: 0.8530\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.4263 - accuracy: 0.8637 - val_loss: 0.4263 - val_accuracy: 0.8632\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.3922 - accuracy: 0.8740 - val_loss: 0.3978 - val_accuracy: 0.8718\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.3630 - accuracy: 0.8822 - val_loss: 0.3762 - val_accuracy: 0.8746\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.3389 - accuracy: 0.8892 - val_loss: 0.3569 - val_accuracy: 0.8758\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.3176 - accuracy: 0.8953 - val_loss: 0.3417 - val_accuracy: 0.8810\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.2998 - accuracy: 0.8989 - val_loss: 0.3293 - val_accuracy: 0.8806\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.2839 - accuracy: 0.9047 - val_loss: 0.3190 - val_accuracy: 0.8826\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.2708 - accuracy: 0.9067 - val_loss: 0.3115 - val_accuracy: 0.8840\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.2584 - accuracy: 0.9111 - val_loss: 0.3025 - val_accuracy: 0.8854\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.2472 - accuracy: 0.9148 - val_loss: 0.2967 - val_accuracy: 0.8860\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.2374 - accuracy: 0.9179 - val_loss: 0.2914 - val_accuracy: 0.8892\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.2280 - accuracy: 0.9212 - val_loss: 0.2870 - val_accuracy: 0.8896\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.2194 - accuracy: 0.9255 - val_loss: 0.2830 - val_accuracy: 0.8910\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.2119 - accuracy: 0.9266 - val_loss: 0.2805 - val_accuracy: 0.8900\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.2062 - accuracy: 0.9281 - val_loss: 0.2768 - val_accuracy: 0.8910\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1976 - accuracy: 0.9319 - val_loss: 0.2759 - val_accuracy: 0.8906\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.1914 - accuracy: 0.9346 - val_loss: 0.2726 - val_accuracy: 0.8932\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1860 - accuracy: 0.9360 - val_loss: 0.2714 - val_accuracy: 0.8922\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1804 - accuracy: 0.9378 - val_loss: 0.2720 - val_accuracy: 0.8930\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.1747 - accuracy: 0.9396 - val_loss: 0.2705 - val_accuracy: 0.8930\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1697 - accuracy: 0.9419 - val_loss: 0.2697 - val_accuracy: 0.8928\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1663 - accuracy: 0.9432 - val_loss: 0.2683 - val_accuracy: 0.8930\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 0.1600 - accuracy: 0.9452 - val_loss: 0.2686 - val_accuracy: 0.8934\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1556 - accuracy: 0.9474 - val_loss: 0.2681 - val_accuracy: 0.8938\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1521 - accuracy: 0.9485 - val_loss: 0.2676 - val_accuracy: 0.8938\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1477 - accuracy: 0.9492 - val_loss: 0.2689 - val_accuracy: 0.8946\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1438 - accuracy: 0.9513 - val_loss: 0.2682 - val_accuracy: 0.8964\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1410 - accuracy: 0.9521 - val_loss: 0.2689 - val_accuracy: 0.8956\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1366 - accuracy: 0.9550 - val_loss: 0.2705 - val_accuracy: 0.8954\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.1331 - accuracy: 0.9571 - val_loss: 0.2704 - val_accuracy: 0.8942\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1300 - accuracy: 0.9566 - val_loss: 0.2727 - val_accuracy: 0.8944\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1273 - accuracy: 0.9585 - val_loss: 0.2724 - val_accuracy: 0.8946\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1237 - accuracy: 0.9597 - val_loss: 0.2741 - val_accuracy: 0.8956\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 0.2771 - val_accuracy: 0.8946\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.1171 - accuracy: 0.9625 - val_loss: 0.2757 - val_accuracy: 0.8948\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1141 - accuracy: 0.9640 - val_loss: 0.2775 - val_accuracy: 0.8954\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.1113 - accuracy: 0.9657 - val_loss: 0.2796 - val_accuracy: 0.8968\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1084 - accuracy: 0.9658 - val_loss: 0.2819 - val_accuracy: 0.8962\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.1059 - accuracy: 0.9669 - val_loss: 0.2836 - val_accuracy: 0.8964\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.1031 - accuracy: 0.9677 - val_loss: 0.2849 - val_accuracy: 0.8952\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1004 - accuracy: 0.9696 - val_loss: 0.2940 - val_accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "history=model.fit(train_data,train_labels,epochs=50,batch_size=512,validation_data=(test_data,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FQWLj-i4dEK"
   },
   "source": [
    "Now we will be evaluating the loss and accuracy of our model on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHLzEJI-RCWF",
    "outputId": "7f3c84cf-fc02-4d9c-c25d-b8ca15b3e95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhtQ2vt44tvd"
   },
   "source": [
    "As we can see our model is giving an accuracy of 89.56% on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using SVM to train the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[861 121]\n",
      " [140 878]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       982\n",
      "    positive       0.88      0.86      0.87      1018\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "Accuracy score: 0.8695\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = df[:5000]\n",
    "test_data = df[5000:7000]\n",
    "\n",
    "# Convert text data into numerical feature vectors using TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['Reviews'])\n",
    "y_train = train_data['Sentiment']\n",
    "X_test = vectorizer.transform(test_data['Reviews'])\n",
    "y_test = test_data['Sentiment']\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[855 127]\n",
      " [149 869]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       982\n",
      "    positive       0.87      0.85      0.86      1018\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Accuracy score: 0.862\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Convert text data into numerical feature vectors using TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['Reviews'])\n",
    "y_train = train_data['Sentiment']\n",
    "X_test = vectorizer.transform(test_data['Reviews'])\n",
    "y_test = test_data['Sentiment']\n",
    "\n",
    "# Train a logistic regression model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 8s 50ms/step - loss: 0.6828 - accuracy: 0.5765 - val_loss: 0.6585 - val_accuracy: 0.6520\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.4898 - accuracy: 0.7770 - val_loss: 0.4367 - val_accuracy: 0.8150\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.2752 - accuracy: 0.8938 - val_loss: 0.4440 - val_accuracy: 0.8280\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1854 - accuracy: 0.9305 - val_loss: 0.4726 - val_accuracy: 0.8250\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 59ms/step - loss: 0.1294 - accuracy: 0.9572 - val_loss: 0.4447 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 9s 73ms/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.5295 - val_accuracy: 0.8270\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 11s 89ms/step - loss: 0.0574 - accuracy: 0.9850 - val_loss: 0.5596 - val_accuracy: 0.8170\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 11s 86ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.4496 - val_accuracy: 0.8160\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 9s 75ms/step - loss: 0.0464 - accuracy: 0.9868 - val_loss: 0.6933 - val_accuracy: 0.8040\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 10s 79ms/step - loss: 0.0386 - accuracy: 0.9898 - val_loss: 0.9047 - val_accuracy: 0.8060\n",
      "63/63 [==============================] - 2s 21ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       982\n",
      "           1       0.82      0.73      0.77      1018\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.78      0.78      0.78      2000\n",
      "weighted avg       0.78      0.78      0.78      2000\n",
      "\n",
      "Accuracy score: 0.7815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data['Reviews'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['Reviews'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Reviews'])\n",
    "\n",
    "# Pad the sequences to make them of equal length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Convert sentiment labels to binary\n",
    "y_train = np.asarray(train_data['Sentiment'].astype('category').cat.codes)\n",
    "y_test = np.asarray(test_data['Sentiment'].astype('category').cat.codes)\n",
    "\n",
    "# Build the LSTM model\n",
    "embedding_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=embedding_size, input_length=maxlen))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8818333333333334\n",
      "F1 score: 0.8818291479614957\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Load the dataset\n",
    "data = reviews\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Reviews'], data['Sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the base classifiers\n",
    "nb = MultinomialNB()\n",
    "lr = LogisticRegression()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Define the ensemble classifier using voting\n",
    "ensemble = VotingClassifier(estimators=[('nb', nb), ('lr', lr), ('svc', svc)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier on the training set\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IMDB_sentiment_analysis_final",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
